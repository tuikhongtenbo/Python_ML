{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07dbca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Union, Any\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5ad6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Excel file to CSV format\n",
    "# excel_path = \"address_full_0712.xlsx\"\n",
    "# csv_path = \"address_full_0712.csv\"\n",
    "\n",
    "# df = pd.read_excel(excel_path)\n",
    "# df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d136678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate multiple JSON files into one\n",
    "input_folder = \"C:\\\\Users\\\\ply58\\\\OneDrive\\\\Tài liệu\\\\PythonML\\\\ML_git\\\\Python_ML\\\\BaitapDS108\\\\Lab 5\\\\LLMs Data\"\n",
    "output_file = \"full_output.json\"\n",
    "\n",
    "json_files = [f for f in os.listdir(input_folder) if f.endswith(\".json\")]\n",
    "json_files.sort()  \n",
    "\n",
    "all_data = []\n",
    "\n",
    "for file_name in json_files:\n",
    "    file_path = os.path.join(input_folder, file_name)\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            obj = json.loads(line.strip())\n",
    "            all_data.append(obj)\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f_out:\n",
    "    for item in all_data:\n",
    "        f_out.write(json.dumps(item, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e1785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset ID in the concatenated JSON file\n",
    "def reset_ids(input_file: str, output_file: str):\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = [json.loads(line) for line in f]\n",
    "\n",
    "    for new_id, entry in enumerate(lines):\n",
    "        entry[\"Id\"] = new_id\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for entry in lines:\n",
    "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "reset_ids(\"full_output.json\", \"full_output_by_llama.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fa2034",
   "metadata": {},
   "source": [
    "Đến đây, em sẽ dùng address data ở: https://github.com/ThangLeQuoc/vietnamese-provinces-database để lọc các thành phố/tỉnh và các cấp đơn vị thấp hơn, trước tiên em sẽ xử lý bộ data trên, lọc và trích xuất các tên tỉnh/thành phố và quận/huyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce40d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HỐNG KÊ TỔNG QUAN\n",
      "Tổng số đơn vị hành chính: 10794\n",
      "- Cấp tỉnh/thành phố: 63\n",
      "- Cấp huyện/quận: 696\n",
      "- Cấp xã/phường: 10035\n",
      "\n",
      "THỐNG KÊ CHI TIẾT\n",
      "Cấp tỉnh/thành phố:\n",
      "- Tỉnh: 57\n",
      "- Thành phố trực thuộc TW: 6\n",
      "\n",
      "Cấp huyện/quận:\n",
      "- Huyện: 508\n",
      "- Quận: 49\n",
      "- Thành phố thuộc tỉnh: 87\n",
      "- Thị xã: 52\n",
      "- Đơn vị hành chính khác cấp huyện: 0\n",
      "\n",
      "Cấp xã/phường:\n",
      "- Phường: 1726\n",
      "- Xã: 7692\n",
      "- Thị trấn: 617\n"
     ]
    }
   ],
   "source": [
    "# def count_administrative_units(data: Union[Dict, List[Dict]]) -> Dict[str, Dict[str, int]]:\n",
    "#     counts = {\n",
    "#         'provinces': 0,\n",
    "#         'districts': 0,\n",
    "#         'wards': 0,\n",
    "#         'total': 0\n",
    "#     }\n",
    "    \n",
    "#     detailed_counts = {\n",
    "#         # Cấp tỉnh/thành phố\n",
    "#         'provinces': 0,\n",
    "#         'municipalities': 0,\n",
    "        \n",
    "#         # Cấp huyện/quận\n",
    "#         'districts': 0,\n",
    "#         'municipal_cities': 0,\n",
    "#         'urban_districts': 0,\n",
    "#         'district_level_towns': 0,\n",
    "#         'provincial_districts': 0,\n",
    "        \n",
    "#         # Cấp xã/phường\n",
    "#         'wards': 0,\n",
    "#         'communes': 0,\n",
    "#         'commune_level_towns': 0\n",
    "#     }\n",
    "    \n",
    "#     def count_units(units: Union[Dict, List[Dict]], level: str) -> None:\n",
    "#         nonlocal counts, detailed_counts\n",
    "  \n",
    "#         if isinstance(units, dict):\n",
    "#             units = [units]\n",
    "#         elif not isinstance(units, list):\n",
    "#             return\n",
    "            \n",
    "#         for unit in units:\n",
    "#             counts['total'] += 1\n",
    "            \n",
    "#             if level == 'province':\n",
    "#                 counts['provinces'] += 1\n",
    "                \n",
    "#                 # Phân loại cấp tỉnh\n",
    "#                 unit_type = unit.get('AdministrativeUnitShortName', '').lower()\n",
    "#                 if 'thành phố' in unit_type:\n",
    "#                     detailed_counts['municipalities'] += 1\n",
    "#                 else:\n",
    "#                     detailed_counts['provinces'] += 1\n",
    "                \n",
    "#                 # district \n",
    "#                 if 'District' in unit and isinstance(unit['District'], list) and len(unit['District']) > 0:\n",
    "#                     count_units(unit['District'], 'district')\n",
    "                    \n",
    "#             elif level == 'district':\n",
    "#                 counts['districts'] += 1\n",
    "                \n",
    "#                 # Phân loại cấp huyện/quận\n",
    "#                 unit_type = unit.get('AdministrativeUnitShortName', '').lower()\n",
    "#                 if 'quận' in unit_type:\n",
    "#                     detailed_counts['urban_districts'] += 1\n",
    "#                 elif 'thành phố' in unit_type:\n",
    "#                     detailed_counts['municipal_cities'] += 1\n",
    "#                 elif 'thị xã' in unit_type:\n",
    "#                     detailed_counts['district_level_towns'] += 1\n",
    "#                 elif 'huyện' in unit_type:\n",
    "#                     detailed_counts['districts'] += 1\n",
    "#                 else:\n",
    "#                     detailed_counts['provincial_districts'] += 1\n",
    "                \n",
    "#                 # ward \n",
    "#                 if 'Ward' in unit and isinstance(unit['Ward'], list) and len(unit['Ward']) > 0:\n",
    "#                     count_units(unit['Ward'], 'ward')\n",
    "                    \n",
    "#             elif level == 'ward':\n",
    "#                 counts['wards'] += 1\n",
    "                \n",
    "#                 # Phân loại cấp xã/phường\n",
    "#                 unit_type = unit.get('AdministrativeUnitShortName', '').lower()\n",
    "#                 if 'phường' in unit_type:\n",
    "#                     detailed_counts['wards'] += 1\n",
    "#                 elif 'xã' in unit_type:\n",
    "#                     detailed_counts['communes'] += 1\n",
    "#                 elif 'thị trấn' in unit_type:\n",
    "#                     detailed_counts['commune_level_towns'] += 1\n",
    "    \n",
    "#     #  cấp tỉnh\n",
    "#     count_units(data, 'province')\n",
    "    \n",
    "#     return {\n",
    "#         'summary': counts,\n",
    "#         'detailed': detailed_counts\n",
    "#     }\n",
    "\n",
    "# def process_json_file(json_data: Union[str, Dict, List]) -> Union[Dict, None]:\n",
    "#     if isinstance(json_data, str):\n",
    "#         data = json.loads(json_data)\n",
    "#     else:\n",
    "#         data = json_data\n",
    "    \n",
    "#     # Đếm các đơn vị\n",
    "#     result = count_administrative_units(data)\n",
    "#     return result\n",
    "\n",
    "# def load_json_from_file(file_path: str) -> Union[Dict, None]:\n",
    "#     with open(file_path, 'r', encoding='utf-8') as file:\n",
    "#         data = json.load(file)\n",
    "#         return process_json_file(data)\n",
    "\n",
    "# def display_results(result: Dict) -> None:\n",
    "#     print('HỐNG KÊ TỔNG QUAN')\n",
    "#     print(f\"Tổng số đơn vị hành chính: {result['summary']['total']}\")\n",
    "#     print(f\"- Cấp tỉnh/thành phố: {result['summary']['provinces']}\")\n",
    "#     print(f\"- Cấp huyện/quận: {result['summary']['districts']}\")\n",
    "#     print(f\"- Cấp xã/phường: {result['summary']['wards']}\")\n",
    "    \n",
    "#     print('\\nTHỐNG KÊ CHI TIẾT')\n",
    "#     print('Cấp tỉnh/thành phố:')\n",
    "#     print(f\"- Tỉnh: {result['detailed']['provinces']}\")\n",
    "#     print(f\"- Thành phố trực thuộc TW: {result['detailed']['municipalities']}\")\n",
    "    \n",
    "#     print('\\nCấp huyện/quận:')\n",
    "#     print(f\"- Huyện: {result['detailed']['districts']}\")\n",
    "#     print(f\"- Quận: {result['detailed']['urban_districts']}\")\n",
    "#     print(f\"- Thành phố thuộc tỉnh: {result['detailed']['municipal_cities']}\")\n",
    "#     print(f\"- Thị xã: {result['detailed']['district_level_towns']}\")\n",
    "#     print(f\"- Đơn vị hành chính khác cấp huyện: {result['detailed']['provincial_districts']}\")\n",
    "    \n",
    "#     print('\\nCấp xã/phường:')\n",
    "#     print(f\"- Phường: {result['detailed']['wards']}\")\n",
    "#     print(f\"- Xã: {result['detailed']['communes']}\")\n",
    "#     print(f\"- Thị trấn: {result['detailed']['commune_level_towns']}\")\n",
    "\n",
    "# def export_results_to_json(result: Dict, output_file: str) -> None:\n",
    "#     with open(output_file, 'w', encoding='utf-8') as file:\n",
    "#         json.dump(result, file, ensure_ascii=False, indent=2)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     file_path = \"full_json_generated_data_vn_units.json\"\n",
    "#     result = load_json_from_file(file_path)\n",
    "    \n",
    "#     if result:\n",
    "#         display_results(result)\n",
    "        \n",
    "#         output_file = \"admin_units_count_result.json\"\n",
    "#         export_results_to_json(result, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30a44a7",
   "metadata": {},
   "source": [
    "Xóa bỏ các đặc trưng không cần trong bài này của bộ data của nhóm tác giả có link github của data: https://github.com/ThangLeQuoc/vietnamese-provinces-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57b56f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_unit_data(data):\n",
    "\n",
    "    if isinstance(data, list):\n",
    "        filtered_list = []\n",
    "        for item in data:\n",
    "            filtered_item = filter_unit_data(item)\n",
    "            if filtered_item: \n",
    "                filtered_list.append(filtered_item)\n",
    "        return filtered_list\n",
    "    elif isinstance(data, dict):\n",
    "        filtered_dict = {}\n",
    "        if \"Type\" in data:\n",
    "            filtered_dict[\"Type\"] = data[\"Type\"]\n",
    "        if \"Name\" in data:\n",
    "            filtered_dict[\"Name\"] = data[\"Name\"]\n",
    "        if \"FullName\" in data:\n",
    "            filtered_dict[\"FullName\"] = data[\"FullName\"]\n",
    "\n",
    "        if \"District\" in data and isinstance(data[\"District\"], list):\n",
    "            filtered_districts = filter_unit_data(data[\"District\"])\n",
    "            if filtered_districts:\n",
    "                filtered_dict[\"District\"] = filtered_districts\n",
    "        \n",
    "        if \"Ward\" in data and isinstance(data[\"Ward\"], list):\n",
    "            filtered_wards = filter_unit_data(data[\"Ward\"])\n",
    "            if filtered_wards:\n",
    "                filtered_dict[\"Ward\"] = filtered_wards\n",
    "        \n",
    "        return filtered_dict\n",
    "    return data \n",
    "\n",
    "input_file_path = \"full_json_generated_data_vn_units.json\"\n",
    "output_file_path = \"filtered_vn_units.json\"\n",
    "\n",
    "with open(input_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    original_data = json.load(f)\n",
    "\n",
    "filtered_data = filter_unit_data(original_data)\n",
    "\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(filtered_data, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56c64ac",
   "metadata": {},
   "source": [
    "#### Province"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5346a1f5",
   "metadata": {},
   "source": [
    "Vì những addresses có tên thành phố/tên tỉnh thì các đơn vị hành chính nhỏ hơn nó có thể xác định và verify dễ hơn do tính duy nhất, những addresses mà không có đơn vị hành chính là thành phố và tên tỉnh thì vẫn giữ nguyên vì không có đủ bằng chứng "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eb21e7",
   "metadata": {},
   "source": [
    "Tạo file \"provinces.json\" gồm các tên tỉnh/thành phố"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbdeae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_provinces_and_municipalities(input_file: str, output_file: str):\n",
    "    provinces_data = []\n",
    "    \n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    if isinstance(data, list):\n",
    "        for item in data:\n",
    "            if isinstance(item, dict) and \"Type\" in item:\n",
    "                if item[\"Type\"] == \"province\" or item[\"Type\"] == \"municipality\":\n",
    "                    provinces_data.append(item[\"Name\"]) \n",
    "        \n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f_out:\n",
    "            json.dump(provinces_data, f_out, ensure_ascii=False, indent=2)\n",
    "\n",
    "input_json_file = \"filtered_vn_units.json\"\n",
    "output_json_file = \"provinces.json\"\n",
    "filter_provinces_and_municipalities(input_json_file, output_json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fc8e92",
   "metadata": {},
   "source": [
    "Tạo file \"addresses_modification.json\" để thực hiện xử lý các câu đã lọc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc349971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_provinces_in_sentences(provinces_file, sentences_file, output_addresses_with_ids_file):\n",
    "    with open(provinces_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        province_names = json.load(f)\n",
    "\n",
    "    province_names_lower = [name.lower() for name in province_names]\n",
    "    special_cities = [\"hà nội\", \"hồ chí minh\", \"đà nẵng\", \"cần thơ\", \"huế\", \"hải phòng\"]\n",
    "\n",
    "    addresses_for_modification = []\n",
    "\n",
    "    with open(sentences_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line.strip())\n",
    "            if \"Sentence\" not in data or not isinstance(data[\"Sentence\"], str):\n",
    "                continue\n",
    "\n",
    "            sentence = data[\"Sentence\"]\n",
    "            sentence_lower = sentence.lower()\n",
    "\n",
    "            parts = sentence_lower.rsplit(\",\", 1)\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "\n",
    "            after_comma = parts[1].strip()\n",
    "            normalized = after_comma.replace(\"tỉnh\", \"\").replace(\"thành phố\", \"\").strip()\n",
    "\n",
    "            if normalized not in province_names_lower:\n",
    "                continue  \n",
    "\n",
    "            found_wrong_match = False\n",
    "            for prov in province_names_lower:\n",
    "                valid_forms = [\n",
    "                    prov,\n",
    "                    f\"tỉnh {prov}\",\n",
    "                    f\"thành phố {prov}\"\n",
    "                ]\n",
    "\n",
    "                wrong_matches = re.findall(r\"\\btỉnh\\s+[^\\s,]+(?:\\s+[^\\s,]+)*\\b\", sentence_lower)\n",
    "                for match in wrong_matches:\n",
    "                    if not any(match.strip() == valid for valid in valid_forms):\n",
    "                        found_wrong_match = True\n",
    "                        break\n",
    "                if found_wrong_match:\n",
    "                    break\n",
    "\n",
    "            if found_wrong_match:\n",
    "                continue  \n",
    "\n",
    "            addresses_for_modification.append(data)\n",
    "\n",
    "    with open(output_addresses_with_ids_file, \"w\", encoding=\"utf-8\") as f_ids_out:\n",
    "        json.dump(addresses_for_modification, f_ids_out, ensure_ascii=False, indent=2)\n",
    "\n",
    "        \n",
    "provinces_json_file = \"provinces.json\"\n",
    "full_output_json_file = \"full_output_by_llama.json\"\n",
    "output_addresses_with_ids_file = \"addresses_modification.json\"\n",
    "\n",
    "find_provinces_in_sentences(provinces_json_file, full_output_json_file, output_addresses_with_ids_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030573da",
   "metadata": {},
   "source": [
    "Thêm các tiền tố như Tỉnh và Thành phố cho các câu đã được lọc và lưu vào file \"addresses_with_prefix.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d9244b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_province_prefix_if_missing(addresses_file, provinces_file, output_file):\n",
    "    # Danh sách 6 thành phố trực thuộc trung ương \n",
    "    special_cities = [\"hà nội\", \"hồ chí minh\", \"đà nẵng\", \"cần thơ\", \"huế\", \"hải phòng\"]\n",
    "\n",
    "    # Provinces file\n",
    "    with open(provinces_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        provinces = json.load(f)\n",
    "    provinces_lower = [p.lower() for p in provinces]\n",
    "\n",
    "    # addresses file\n",
    "    with open(addresses_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        addresses = json.load(f)\n",
    "\n",
    "    updated_addresses = []\n",
    "    for item in addresses:\n",
    "        sentence = item.get(\"Sentence\", \"\")\n",
    "        sentence_lower = sentence.lower()\n",
    "        modified = False\n",
    "\n",
    "        for province in provinces_lower:\n",
    "            if province in sentence_lower:\n",
    "                # Check if the province is already have prefix\n",
    "                if f\"tỉnh {province}\" in sentence_lower or f\"thành phố {province}\" in sentence_lower:\n",
    "                    break \n",
    "                else:\n",
    "                    # Add prefix if missing\n",
    "                    if province in special_cities:\n",
    "                        prefix = \"Thành phố \"\n",
    "                    else:\n",
    "                        prefix = \"Tỉnh \"\n",
    "\n",
    "                    index = sentence_lower.find(province)\n",
    "                    original_text = sentence[index: index + len(province)]\n",
    "                    sentence = sentence[:index] + prefix + original_text + sentence[index + len(province):]\n",
    "                    item[\"Sentence\"] = sentence\n",
    "                    modified = True\n",
    "                    break\n",
    "\n",
    "        updated_addresses.append(item)\n",
    "\n",
    "    # Saving\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f_out:\n",
    "        json.dump(updated_addresses, f_out, ensure_ascii=False, indent=2)\n",
    "\n",
    "addresses_file=\"addresses_modification.json\"\n",
    "provinces_file=\"provinces.json\"\n",
    "output_file=\"addresses_with_prefix.json\"\n",
    "add_province_prefix_if_missing(addresses_file, provinces_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5aa6e9",
   "metadata": {},
   "source": [
    "#### District"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9eec93",
   "metadata": {},
   "source": [
    "Lọc ra tên các cấp quận/huyện/thị xã/thành phố (thuộc tỉnh) và lưu vào \"districts.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ab1b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_district_names(input_file: str, output_file: str):\n",
    "\n",
    "    valid_types = {\n",
    "        \"district\",\n",
    "        \"urban district\",\n",
    "        \"district-level town\",\n",
    "        \"provincial city\"\n",
    "    }\n",
    "\n",
    "    district_entries = []\n",
    "\n",
    "    # Input file\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for province in data:\n",
    "        province_name = province.get(\"Name\", \"\")       \n",
    "        for district in province.get(\"District\", []):\n",
    "            district_type = district.get(\"Type\")\n",
    "            name = district.get(\"Name\")\n",
    "            full_name = district.get(\"FullName\")\n",
    "\n",
    "            if district_type in valid_types and name and full_name:\n",
    "                district_entries.append({\n",
    "                    \"Province\": province_name,  \n",
    "                    \"Name\": name,\n",
    "                    \"FullName\": full_name\n",
    "                })\n",
    "\n",
    "    # Drop duplicates by Name\n",
    "    seen = set()\n",
    "    unique_districts = []\n",
    "    for entry in district_entries:\n",
    "        key = (entry[\"Name\"], entry[\"Province\"])\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            unique_districts.append(entry)\n",
    "\n",
    "    # Sort by Province, Name\n",
    "    unique_districts.sort(key=lambda x: (x[\"Province\"], x[\"Name\"]))\n",
    "\n",
    "    # Saving\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f_out:\n",
    "        json.dump(unique_districts, f_out, ensure_ascii=False, indent=2)\n",
    "\n",
    "input_file = \"filtered_vn_units.json\"\n",
    "output_file = \"districts.json\"\n",
    "extract_district_names(input_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eef11d5",
   "metadata": {},
   "source": [
    "Với \"districs.json\", sửa tiền tố của cấp District"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee46fa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_province_name(name: str):\n",
    "    name = name.lower().strip()\n",
    "    name = name.replace(\"tỉnh\", \"\").replace(\"thành phố\", \"\").strip()\n",
    "    return name\n",
    "\n",
    "def replace_district_names(address_file: str, districts_file: str, output_file: str, field: str = \"Sentence\"):\n",
    "    # Load dữ liệu\n",
    "    with open(address_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        addresses = json.load(f)\n",
    "\n",
    "    with open(districts_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        districts = json.load(f)\n",
    "\n",
    "    prefix_keywords = {\"quận\", \"huyện\", \"thành phố\", \"thị xã\"}\n",
    "\n",
    "    district_dict = {}\n",
    "    for d in districts:\n",
    "        name_lower = d[\"Name\"].lower()\n",
    "        district_dict.setdefault(name_lower, []).append(d)\n",
    "\n",
    "    modified_addresses = []\n",
    "    for addr_obj in addresses:\n",
    "        text = addr_obj.get(field, \"\")\n",
    "        parts = [p.strip() for p in text.split(\",\")]\n",
    "\n",
    "        if len(parts) < 2:\n",
    "            modified_addresses.append(addr_obj)\n",
    "            continue\n",
    "\n",
    "        district_candidate = parts[-2]\n",
    "        province_candidate = parts[-1]\n",
    "\n",
    "        has_prefix = any(district_candidate.lower().startswith(prefix) for prefix in prefix_keywords)\n",
    "        if has_prefix:\n",
    "            modified_addresses.append(addr_obj)\n",
    "            continue\n",
    "\n",
    "        name_lower = district_candidate.lower()\n",
    "        if name_lower in district_dict:\n",
    "            matched = False\n",
    "            for district_entry in district_dict[name_lower]:\n",
    "                if normalize_province_name(province_candidate) == normalize_province_name(district_entry[\"Province\"]):\n",
    "                    parts[-2] = district_entry[\"FullName\"]\n",
    "                    matched = True\n",
    "                    break\n",
    "\n",
    "        addr_obj[field] = \", \".join(parts)\n",
    "        modified_addresses.append(addr_obj)\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(modified_addresses, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "addresses_file = \"addresses_with_prefix.json\"\n",
    "districts_file = \"districts.json\"\n",
    "output_file = \"addresses_with_prefix_districts.json\"\n",
    "replace_district_names(addresses_file, districts_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461ffe1f",
   "metadata": {},
   "source": [
    "#### Ward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e4f995",
   "metadata": {},
   "source": [
    "Lọc ra các cấp Xã/Phường/Thị trấn và lưu vào wards.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dff121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ward_names(input_file: str, output_file: str):\n",
    "\n",
    "    valid_types = {\n",
    "        \"ward\",                # Phường\n",
    "        \"commune\",             # Xã\n",
    "        \"commune-level town\"   # Thị trấn\n",
    "    }\n",
    "\n",
    "    ward_entries = []\n",
    "\n",
    "    # Input file\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for province in data:\n",
    "        province_name = province.get(\"Name\")\n",
    "        for district in province.get(\"District\", []):\n",
    "            district_name = district.get(\"Name\")\n",
    "            for ward in district.get(\"Ward\", []):\n",
    "                ward_type = ward.get(\"Type\")\n",
    "                name = ward.get(\"Name\")\n",
    "                full_name = ward.get(\"FullName\")\n",
    "\n",
    "                if ward_type in valid_types and name and full_name:\n",
    "                    ward_entries.append({\n",
    "                        \"Name\": name,\n",
    "                        \"FullName\": full_name,\n",
    "                        \"Province\": province_name,\n",
    "                        \"District\": district_name\n",
    "                    })\n",
    "\n",
    "    # Drop duplicates by Name, Province, District\n",
    "    seen = set()\n",
    "    unique_wards = []\n",
    "    for entry in ward_entries:\n",
    "        key = (entry[\"Name\"], entry[\"Province\"], entry[\"District\"])\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            unique_wards.append(entry)\n",
    "\n",
    "    # Sort by Name \n",
    "    unique_wards.sort(key=lambda x: (x[\"Name\"], x[\"Province\"], x[\"District\"]))\n",
    "\n",
    "    # Saving\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f_out:\n",
    "        json.dump(unique_wards, f_out, ensure_ascii=False, indent=2)\n",
    "\n",
    "input_file = \"filtered_vn_units.json\"\n",
    "output_file = \"wards.json\"\n",
    "extract_ward_names(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d744dbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_ward_names(address_file: str, wards_file: str, output_file: str, field: str = \"Sentence\"):\n",
    "    # Address file\n",
    "    with open(address_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        addresses = json.load(f)\n",
    "    # Ward file\n",
    "    with open(wards_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        wards = json.load(f)\n",
    "    # Sort wards by length of Name in descending order\n",
    "    sorted_wards = sorted(wards, key=lambda w: len(w[\"Name\"]), reverse=True)\n",
    "\n",
    "    prefix_keywords = [\"phường\", \"xã\", \"thị trấn\"]\n",
    "    modified_addresses = []\n",
    "\n",
    "    # Replace ward names in addresses\n",
    "    for addr_obj in addresses:\n",
    "        original_text = addr_obj.get(field, \"\")\n",
    "        text = original_text\n",
    "        for ward in sorted_wards:\n",
    "            name = ward[\"Name\"]\n",
    "            full_name = ward[\"FullName\"]\n",
    "            district = ward[\"District\"].lower()\n",
    "            province = ward[\"Province\"].lower()\n",
    "\n",
    "            # If the full name is already in the text -> skip \n",
    "            if re.search(re.escape(full_name), text, flags=re.IGNORECASE):\n",
    "                continue\n",
    "\n",
    "            # Find the ward name in the text\n",
    "            pattern = r'(?<!\\w)' + re.escape(name) + r'(?!\\w)'\n",
    "            match = re.search(pattern, text, flags=re.IGNORECASE)\n",
    "\n",
    "            # If found, check the context before and after the match\n",
    "            if match:\n",
    "                before_text = text[max(0, match.start() - 20):match.start()].lower()\n",
    "                if any(keyword in before_text.split()[-3:] for keyword in prefix_keywords):\n",
    "                    continue\n",
    "\n",
    "                after_text = text[match.end():].lower()\n",
    "                has_district = district in after_text\n",
    "                has_province = province in after_text\n",
    "\n",
    "                if has_district and has_province:\n",
    "                    text = re.sub(pattern, full_name, text, flags=re.IGNORECASE)\n",
    "                    break  \n",
    "\n",
    "        addr_obj[field] = text\n",
    "        modified_addresses.append(addr_obj)\n",
    "\n",
    "    # Saving\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(modified_addresses, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "address_file=\"addresses_with_prefix_districts.json\"\n",
    "wards_file=\"wards.json\"\n",
    "output_file=\"addresses_with_prefix_wards.json\"\n",
    "replace_ward_names(address_file, wards_file,output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6009f23a",
   "metadata": {},
   "source": [
    "#### Result json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e05f01de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_output_by_llama.json\n",
    "with open(\"full_output_by_llama.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read().strip()\n",
    "    if content.startswith(\"[\"):\n",
    "        full_data = json.loads(content)\n",
    "    else:\n",
    "        full_data = [json.loads(line) for line in content.splitlines() if line.strip()]\n",
    "\n",
    "# addresses_with_prefix_wards.json\n",
    "with open(\"addresses_with_prefix_wards.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    ward_content = f.read().strip()\n",
    "    if ward_content.startswith(\"[\"):\n",
    "        ward_data = json.loads(ward_content)\n",
    "    else:\n",
    "        ward_data = [json.loads(line) for line in ward_content.splitlines() if line.strip()]\n",
    "\n",
    "# Create a dictionary to map Id to Sentence from ward_data\n",
    "ward_dict = {entry[\"Id\"]: entry[\"Sentence\"] for entry in ward_data if \"Id\" in entry and \"Sentence\" in entry}\n",
    "\n",
    "# Replace \"Sentence\" in full_data with corresponding values from ward_dict\n",
    "for item in full_data:\n",
    "    if \"Id\" in item and item[\"Id\"] in ward_dict:\n",
    "        item[\"Sentence\"] = ward_dict[item[\"Id\"]]\n",
    "\n",
    "# result.json\n",
    "with open(\"result.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(full_data, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866f307f",
   "metadata": {},
   "source": [
    "Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08616e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Add_id(input_file, output_file, fields=None):\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    output_data = []\n",
    "\n",
    "    if isinstance(data, list) and all(isinstance(item, str) for item in data):\n",
    "        for i, name in enumerate(data, 1):\n",
    "            output_data.append({\n",
    "                \"Id\": i,\n",
    "                \"Name\": name\n",
    "            })\n",
    "    elif isinstance(data, list) and all(isinstance(item, dict) for item in data):\n",
    "        for i, item in enumerate(data, 1):\n",
    "            entry = {field: item[field] for field in fields if field in item}\n",
    "            entry[\"Id\"] = i\n",
    "            output_data.append(entry)\n",
    "    else:\n",
    "        raise ValueError(f\"Không nhận diện được cấu trúc trong file {input_file}\")\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f_out:\n",
    "        json.dump(output_data, f_out, ensure_ascii=False, indent=2)\n",
    "\n",
    "Add_id(\"provinces.json\", \"provinces_id.json\")\n",
    "Add_id(\"districts.json\", \"districts_id.json\", fields=[\"Name\", \"Province\"])\n",
    "Add_id(\"wards.json\", \"wards_id.json\", fields=[\"Name\", \"District\", \"Province\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "321bdfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"provinces_id.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    provinces = json.load(f)\n",
    "\n",
    "with open(\"districts_id.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    districts = json.load(f)\n",
    "\n",
    "with open(\"wards_id.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    wards = json.load(f)\n",
    "\n",
    "with open(\"result.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Create maps for provinces, districts, and wards\n",
    "province_map = {p[\"Name\"].lower(): {\"Id\": p[\"Id\"], \"Name\": p[\"Name\"]} for p in provinces}\n",
    "\n",
    "district_map = {}\n",
    "for d in districts:\n",
    "    province = d[\"Province\"]\n",
    "    if province not in district_map:\n",
    "        district_map[province] = []\n",
    "    district_map[province].append(d)\n",
    "\n",
    "ward_map = {}\n",
    "for w in wards:\n",
    "    key = (w[\"Province\"], w[\"District\"])\n",
    "    if key not in ward_map:\n",
    "        ward_map[key] = []\n",
    "    ward_map[key].append(w)\n",
    "\n",
    "def normalize(text):\n",
    "    return text.lower().strip()\n",
    "\n",
    "def add_id_to_sentence(entry):\n",
    "    sentence = entry[\"Sentence\"]\n",
    "    parts = [part.strip() for part in sentence.split(\",\")]\n",
    "    if len(parts) < 2:\n",
    "        return entry\n",
    "\n",
    "    # Take the last part as the province name\n",
    "    last = normalize(parts[-1])\n",
    "    province_name = None\n",
    "    for name in province_map:\n",
    "        if name in last:\n",
    "            province_name = province_map[name][\"Name\"]\n",
    "            entry[\"city_id\"] = province_map[name][\"Id\"]\n",
    "            break\n",
    "\n",
    "    if not province_name:\n",
    "        return entry\n",
    "\n",
    "    # Check districts\n",
    "    if len(parts) >= 3:\n",
    "        district_candidate = normalize(parts[-2])\n",
    "        for d in district_map.get(province_name, []):\n",
    "            if normalize(d[\"Name\"]) in district_candidate:\n",
    "                entry[\"district_id\"] = d[\"Id\"]\n",
    "                district_name = d[\"Name\"]\n",
    "\n",
    "                # Check wards\n",
    "                if len(parts) >= 4:\n",
    "                    ward_candidate = normalize(parts[-3])\n",
    "                    for w in ward_map.get((province_name, district_name), []):\n",
    "                        if normalize(w[\"Name\"]) in ward_candidate:\n",
    "                            entry[\"ward_id\"] = w[\"Id\"]\n",
    "                            break\n",
    "                break\n",
    "\n",
    "    return entry\n",
    "\n",
    "# ID\n",
    "updated_results = [add_id_to_sentence(entry) for entry in results]\n",
    "\n",
    "# Saving\n",
    "with open(\"result_id.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(updated_results, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96248435",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"result_id.json\", \"r\", encoding=\"utf-8-sig\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "with open(\"result_id.csv\", \"w\", newline=\"\", encoding=\"utf-8-sig\") as csvfile:\n",
    "    fieldnames = [\"id\", \"full_address\", \"city_id\", \"district_id\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for entry in data:\n",
    "        writer.writerow({\n",
    "            \"id\": entry.get(\"Id\", \"\"),\n",
    "            \"full_address\": entry.get(\"Sentence\", \"\"),\n",
    "            \"city_id\": entry.get(\"city_id\", \"\"),\n",
    "            \"district_id\": entry.get(\"district_id\", \"\"),\n",
    "\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5097afa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
